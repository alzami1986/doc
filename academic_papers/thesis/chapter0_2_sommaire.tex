Lorsqu'appliquée à la reconnaissance de visages à partir de séquences vidéo, la classification consiste typiquement à comparer des échantillons d'origine inconnue à des modèles biométriques (i.e., modèles de visages d’individus) conçus à l'aide d'échantillons de référence acquis à l’aide d’un senseur quelconque durant un processus d’inscription. Bien que les classificateurs neuronaux et statistiques offrent une solution flexible à ce type de problème, leur performance est grandement affectée par la disponibilité de données de référence représentatives. L'implication de personnes réelles durant le processus d’acquisition de données biométriques fait en sorte que la collecte et l’analyse de celles-ci sont souvent coûteuses et laborieuses. Bien qu'un nombre limité de données soit initialement disponible, de nouvelles données peuvent être acquises au fil du temps. Toutefois, l’absence de contrôle sur les conditions d’opération de systèmes de reconnaissance de visages et sur la physiologie des sujets à reconnaître a pour effet de soumettre les classificateurs à des environnements de classification complexes et changeants dans le temps.

Cette thèse aborde le problème en proposant un système de classificateurs multiples adaptatif (AMCS, pour «adaptive multiclassifier system») qui permet un apprentissage incrémental de nouvelles données disponibles durant l’inscription et la mise à jour de modèles biométriques. L'AMCS utilise une stratégie d’apprentissage incrémental supervisé fondée sur l’optimisation dynamique avec essaims de particules (DPSO, pour «dynamic particle swarm optimization») qui permet l’évolution d’un essaim de réseaux de neurones fuzzy ARTMAP (FAM) à l’aide de nouvelles données sans corrompre les connaissances acquises. En associant chaque particule dans un espace de recherche d’hyperparamètres à un réseau FAM, cette dernière adapte la plasticité (ou dynamique d’apprentissage) des classificateurs en co-optimisant tous leurs paramètres – hyperparamètres, poids synaptiques et architecture – afin de maximiser la performance  (exactitude), tout en minimisant le coût computationnel et les ressources en mémoire nécessaires. La réalisation de l’AMCS est le résultat de l'étude et de la caractérisation de la relation entre les environnements de classification et d’optimisation définis à l’aide de cette approche.

Une version initiale de la stratégie d’apprentissage incrémental est appliquée à un système de classification adaptatif (ACS, pour «adaptive classification system»), où la performance d’un seul réseau de neurones FAM est maximisée. Dans ce contexte, il est démontré qu'il faut reconsidérer deux aspects de la définition originale d’un système de classification pouvant faire un apprentissage incrémental. Non seulement la dynamique d’apprentissage du classificateur doit être adaptée afin de maintenir un haut niveau de performance dans le temps, mais certaines données acquises précédemment doivent être utilisées durant cette adaptation. La validité de cette nouvelle définition est vérifiée en démontrant empiriquement que l’adaptation de réseaux FAM durant un apprentissage incrémental constitue un problème d’optimisation dynamique de type III, où la valeur et la position des optima locaux changent dans le temps. Les résultats démontrent également la nécessité d’une mémoire à long terme (LTM, pour «long term memory») qui emmagasine certaines données acquises précédemment à des fins de validation et d'estimation des performances sans biais durant le processus d'apprentissage.

La stratégie d’apprentissage incrémental est ensuite modifiée afin de faire évoluer un essaim (ou une réserve) de réseaux FAM d’un AMCS avec la possibilité d'en faire un ensemble. Ceci permet d’aborder un facteur clé du bon fonctionnement de ceux-ci : la diversité des classificateurs. 
À l’aide de plusieurs indicateurs de corrélation et de diversité, il est démontré que la diversité génotype (i.e., d’hyperparamètres) dans l'environnement d'optimisation est corrélée avec la diversité des classificateurs dans l'environnement de classification.
À partir de ce résultat, les propriétés d’algorithmes DPSO cherchant à maintenir la diversité génotype des particules afin de repérer et suivre les optima locaux sont utilisées pour générer et évoluer un essaim de classificateurs FAM diversifiés.
Un algorithme de recherche glouton est alors utilisé afin de sélectionner efficacement un ensemble en fonction de la performance et de la diversité sans l’utilisation d’indicateurs de diversité des classificateurs, coûteux à l’utilisation. Tout en ayant une performance comparable, les ensembles résultants utilisent seulement une fraction des ressources nécessaires aux méthodes de référence fondées sur des ensembles et/ou un apprentissage par groupe («batch»).

Finalement, après avoir principalement étudié la relation entre l’environnement de classification et l’espace de recherche, l’espace des objectifs est également considéré durant la conception d’une dernière version des AMCS et d’une stratégie d’apprentissage incrémental. Un algorithme d’optimisation avec essaim de particules par agrégation et nichage dynamique (ADNPSO, pour «aggregated dynamical niching particle swarm optimization») est présenté afin de guider les réseaux FAM en fonction de deux objectifs : la performance des réseaux FAM et leur coût computationnel. Plutôt que de solutionner un problème d’optimisation multi-objectif afin d’en trouver le front de Pareto optimal, l’algorithme ADNPSO cherche à générer une réserve de classificateurs pour lesquels les diversités génotype et phénotype (i.e., d'objectifs) sont maximisées. L’algorithme ADNPSO guide alors les particules vers les différents fronts de Pareto locaux en utilisant l’information disponible dans l’espace de recherche. Les classificateurs sont ensuite catégorisés selon leur taille et emmagasinés dans une archive spécialisée d'après un critère de non-dominance local. Ces deux composantes sont alors intégrées à l'AMCS avec une stratégie d’apprentissage incrémental fondée sur l’ADNPSO.

L'AMCS est prometteur. Utilisé conjointement avec la stratégie d’apprentissage fondée sur l’ADNPSO dans le but de créer un ensemble de réseaux FAM, celui-ci a offert une performance comparable à celle obtenue avec des méthodes d’ensembles utilisant des combinaisons d’optimisation mono-objectif et d’apprentissage incrémental, pour seulement une fraction du coût computationnel.
